---
title: 7th UCSLab Morning Seminar
date: 2019-06-20 00:00:00 Z
description: Notificaion of 7th UCSLab Morning Seminar (on 2019-06-24)
card_title: 7th Morning Seminar
card_teaser: with 5 presentations on 2019-06-24.
card_position: 1
icon: fa-bullhorn
categories: [seminars,06-24-2019-morning-seminar,notification]
sidebar: morning-seminar
layout: default
slug: ms-notification-june-24-2019
permalink: /:categories/:slug.html

---

{% assign product = 'ce' %}

{% include layout/row_start.html %}
{% include layout/col_start.html column="7" %}

## Date
2019-06-24

## Presenters
+ Seong-Yun Jeon (전성윤)
+ Hee-Yong Kwon (권희용)
+ Ye-Byoul Son (손예별)
+ Tae-Hyun Kim (김태현)
+ Jong-Hyuk Im (임종혁)


---
## Presentations

---

### Session 1: [Title](https://inhaucs.github.io/seminars/04-29-2019-morning-seminar/presentation/ms-presentation-jh-apr-29-2019.html)

---

### Session 2: [Title](https://inhaucs.github.io/seminars/04-29-2019-morning-seminar/presentation/ms-presentation-jh-apr-29-2019.html)

---

### Session 3: [Title](https://inhaucs.github.io/seminars/04-29-2019-morning-seminar/presentation/ms-presentation-jh-apr-29-2019.html)

---

### Session 4: [Title](https://inhaucs.github.io/seminars/04-29-2019-morning-seminar/presentation/ms-presentation-jh-apr-29-2019.html)

---

### Session 5: [A4NT: Author Attribute Anonymity by Adversarial Training of Neural Machine Translation](-)

+ Jong-Hyum Im (임종혁)

### Information of the paper [(Link)](https://www.usenix.org/conference/usenixsecurity18/presentation/shetty)
+ Authors: Rakshith Shetty, Bernt Schiele, and Mario Fritz, Max Planck (Institute for Informatics)
+ Conference name: USENIX Security 2018
+ Published date: 2018-08-17
+ [Paper Link](https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-shetty.pdf)


### Abstract
Text-based analysis methods enable an adversary to reveal privacy relevant author attributes such as gender, age and can identify the text's author. Such methods can compromise the privacy of an anonymous author even when the author tries to remove privacy sensitive content. In this paper, we propose an automatic method, called the Adversarial Author Attribute Anonymity Neural Translation ($\text{A}^{4}\text{NT}$), to combat such text-based adversaries. Unlike prior works on obfuscation, we propose a system that is fully automatic and learns to perform obfuscation entirely from the data. This allows us to easily apply the $\text{A}^{4}\text{NT}$ system to obfuscate different author attributes. We propose a sequence-to-sequence language model, inspired by machine translation, and an adversarial training framework to design a system which learns to transform the input text to obfuscate the author attributes without paired data. We also propose and evaluate techniques to impose constraints on our $\text{A}^{4}\text{NT}$ model to preserve the semantics of the input text. $\text{A}^{4}\text{NT}$ learns to make minimal changes to the input to successfully fool author attribute classifiers, while preserving the meaning of the input text. Our experiments on two datasets and three settings show that the proposed method is effective in fooling the attribute classifiers and thus improves the anonymity of authors.

---





{% include date/updated.html %}

{% include layout/col_end.html %}
{% include layout/col_start.html column="4 last push1" %}

{% include layout/row_end.html %}
